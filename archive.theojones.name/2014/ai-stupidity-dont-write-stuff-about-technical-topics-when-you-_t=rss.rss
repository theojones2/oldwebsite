<?xml version="1.0"?>
<rss version="2.0" xmlns:g="http://base.google.com/ns/1.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:geo="http://www.w3.org/2003/01/geo/wgs84_pos#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd">
  <channel>
    <title>AI Stupidity: Don't Write Stuff About Technical Topics When You Have No Idea What You Are Talking About</title>
    <description><![CDATA[Thoughts and Ideas]]></description>
    <itunes:summary><![CDATA[Thoughts and Ideas]]></itunes:summary>
    <link>http://www.theojones.name/2014/ai-stupidity-dont-write-stuff-about-technical-topics-when-you</link>
    <atom:link href="http://withknown.superfeedr.com/" rel="hub"/>
    <atom:link href="http://www.theojones.name/2014/ai-stupidity-dont-write-stuff-about-technical-topics-when-you?_t=rss" rel="self" type="application/rss+xml"/>
    <generator>Known https://withknown.com</generator>
    <item>
      <title>AI Stupidity: Don't Write Stuff About Technical Topics When You Have No Idea What You Are Talking About</title>
      <link>http://www.theojones.name/2014/ai-stupidity-dont-write-stuff-about-technical-topics-when-you</link>
      <guid>http://www.theojones.name/2014/ai-stupidity-dont-write-stuff-about-technical-topics-when-you</guid>
      <pubDate>Fri, 18 Jul 2014 09:00:04 +0000</pubDate>
      <author>Theo Jones</author>
      <description><![CDATA[<div>
        <p>There are some factual errors that are tolerable. There are some other errors that are so wrong that anyone publishes an article with them doesn't know what they are talking about, and thus can be safely ignored as a credible source. One subject where people are very good at making themselves sound like idiots is artificial intelligence. There was the vast media attention given to <a href="http://www.theregister.co.uk/2014/06/09/software_passes_turing_test/">"Captain Cyborg" Kevin Warwick's chat bot</a>, even though ol professor cyborg is a known crackpot in the AI world.</p><p>However, the press still doesn't realize the difference between a computer program that applies a few simple rules to bodies of text, and genuine intelligence.</p><p><a href="http://jezebel.com/instagram-apologizes-for-deleting-plus-size-womans-acco-1605831194">Today's AI PEBAC comes</a> from an article on a liberal blog about someone who got banned from Instagram for seemingly no good reason. The ID10t error comes from the following paragraph.  </p><blockquote>
<p>And before people start computer-splaining about how these companies use an automated system to deal with reports, you can hold your breath. We already know. That system is fucked up. If companies like Facebook can manage to come up with software that knows to spam you with ads for baby clothes right at the time you "liked" your old roommate's post announcing she was pregnant, they sure as shit should be able to come up with a system that doesn't arbitrarily discriminate on who gets deleted and who stays. But thanks for the IT lesson anyway.</p>
</blockquote><p>Why am I writing flamage about this particular passage? This stupidity didn't just stay put. It spread to other websites. I've seen that particular passage quoted as truth -- with all seriousness -- on Huff Post and other news websites. And this vision that it is somehow easy to create a moderation bot that is as good as a human mod and that doesn't fuck up is stupid. A moderation bot is written by the application of a few simple mathematical rules to text processing. In particular these bots often take into account the words used in the posts. The frequency of the varous words can be compared to the frequency of the words in pasts that have been banned by human users. If the bot determines that the text of a suspect user has similar word frequency to known trolls then the banhammer will drop. These programs also often take into account the ratio of complaints, and downvotes to actual account activity, and number of followers. The impression that it shows any deeper intelligence is simply the ELIZA effect. Humans are good at seeing some type of intelligence where none exists. Such as the author of the linked post who thinks that moderation bots express sexism, and can willingly fat shame and intentionally offend Tumblr users (an easy AI problem). As for the "software that knows to spam you with ads for baby clothes right at the time you 'liked' your old roommate's post announcing she was pregnant", those use the exact same methods that the moderation software does. They are also quite error prone, but you tend not to notice their failures as much. The typical person will ignore an irrelevant ad, but will definitely notice the banhammer.</p><p><a href="http://www.theojones.name/tag/eliza" class="p-category" rel="tag">#eliza</a> <a href="http://www.theojones.name/tag/huffpost" class="p-category" rel="tag">#huffpost</a> <a href="http://www.theojones.name/tag/it" class="p-category" rel="tag">#it</a> <a href="http://www.theojones.name/tag/old" class="p-category" rel="tag">#old</a> <a href="http://www.theojones.name/tag/old" class="p-category" rel="tag">#old</a> <a href="http://www.theojones.name/tag/uncategorized" class="p-category" rel="tag">#uncategorized</a></p></div>]]></description>
      <category>#eliza</category>
      <category>#huffpost</category>
      <category>#it</category>
      <category>#old</category>
      <category>#old</category>
      <category>#uncategorized</category>
    </item>
  </channel>
</rss>
